{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import utils as ut\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make def\n",
    "def cart2hom( pts_3d):\n",
    "    \"\"\" Input: nx3 points in Cartesian\n",
    "        Oupput: nx4 points in Homogeneous by pending 1\n",
    "    \"\"\"\n",
    "    n = pts_3d.shape[0]\n",
    "    pts_3d_hom = np.hstack((pts_3d, np.ones((n, 1))))\n",
    "    return pts_3d_hom\n",
    "\n",
    "def project_velo_to_ref( V2C, pts_3d_velo):\n",
    "    pts_3d_velo = cart2hom(pts_3d_velo)  # nx4\n",
    "    return np.dot(pts_3d_velo, np.transpose(V2C))\n",
    "\n",
    "def project_ref_to_rect(R0, pts_3d_ref):\n",
    "    \"\"\" Input and Output are nx3 points \"\"\"\n",
    "    return np.transpose(np.dot(R0, np.transpose(pts_3d_ref)))\n",
    "\n",
    "def project_velo_to_rect( V2C, pts_3d_velo, R0):\n",
    "        pts_3d_ref = project_velo_to_ref(V2C, pts_3d_velo)\n",
    "        return project_ref_to_rect(R0,pts_3d_ref)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make path\n",
    "path_image = \"sample_data/object/image/front/\"\n",
    "path_lidar = \"sample_data/object/roof/\"\n",
    "path_camera = \"sample_data/object/front/\"\n",
    "path_calib = \"sample_data/object/calib/front/\"\n",
    "path_front_left = \"sample_data/object/front_left/\"\n",
    "path_front_right = \"sample_data/object/front_right/\"\n",
    "path_roof = \"sample_data/object/roof/\"\n",
    "image_path_list = os.listdir(path_image)\n",
    "lidar_path_list = os.listdir(path_lidar)\n",
    "camera_path_list = os.listdir(path_camera)\n",
    "calib_path_list = os.listdir(path_calib)\n",
    "front_left_path_list = os.listdir(path_front_left)\n",
    "front_right_path_list = os.listdir(path_front_right)\n",
    "roof_path_list = os.listdir(path_roof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 지정된 경로를 찾을 수 없습니다: '../../라벨링데이터/camera'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m path_check_camera2 \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../원천데이터/camera\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      6\u001b[0m path_check_lidar2 \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../원천데이터/camera\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 8\u001b[0m check_camera_list \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mlistdir(path_check_camera)\n\u001b[0;32m      9\u001b[0m check_lidar_list \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlistdir(path_check_lidar)\n\u001b[0;32m     10\u001b[0m check_camera2_list \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlistdir(path_check_camera)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: '../../라벨링데이터/camera'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path_check_camera = '../../../'\n",
    "path_check_lidar = '../라벨링데이터/lidar'\n",
    "path_check_camera2 = '../원천데이터/camera'\n",
    "path_check_lidar2 = '../원천데이터/camera'\n",
    "\n",
    "check_camera_list = os.listdir(path_check_camera)\n",
    "check_lidar_list = os.listdir(path_check_lidar)\n",
    "check_camera2_list = os.listdir(path_check_camera)\n",
    "check_lidar2_list = os.listdir(path_check_lidar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def make_json_data(path,name):\n",
    "    with open(f'{path}{name}',\"r\") as f:\n",
    "        contents = f.read()\n",
    "        json_data = json.loads(contents)\n",
    "    return json_data\n",
    "def read_calib_Tr_R0(path_calib,image_name):\n",
    "    with open(f'{path_calib}{image_name.split(\".\")[0]}.txt','r') as f:\n",
    "        Tr_velo_to_cam = []\n",
    "        R0 = []\n",
    "        contents_calib = f.readlines()\n",
    "        data_calib = contents_calib[2].split(' ')\n",
    "        data_R0_s = contents_calib[1].split(' ')\n",
    "        data_P2 = contents_calib[0].split(' ')\n",
    "        for calib in data_calib[1:]:\n",
    "            if calib == data_calib[-1]:\n",
    "                Tr_velo_to_cam.append(float(calib[:-1]))\n",
    "            else:\n",
    "                Tr_velo_to_cam.append(float(calib))\n",
    "        for R0s in data_R0_s[1:]:\n",
    "            if R0s == data_R0_s[-1]:\n",
    "                R0.append(float(R0s[:-1]))\n",
    "            else:\n",
    "                R0.append(float(R0s))\n",
    "        R0 = np.reshape(R0, [3, 3])\n",
    "    return Tr_velo_to_cam, R0\n",
    "def aihub_to_kitti_format_camera_cordinate(json_data, image_name,Tr_velo_to_cam, R0, lidar_location):\n",
    "    # make id check list and txt\n",
    "    names = image_name.split(\".\")[0]\n",
    "    names= names.split(\"_\")\n",
    "    name = ''\n",
    "    for i in names:\n",
    "        name+= i\n",
    "    # make image\n",
    "    im = Image.open(f'sample_data/object/image/front/{image_name.split(\".\")[0]}.jpg').convert('RGB')\n",
    "    im.save(f'sample_data/object/translated/image_2/{name}.png','png')\n",
    "    # read velodyne\n",
    "    with open(f'sample_data/object/velodyne/{image_name.split(\".\")[0]}.bin','rb') as f:\n",
    "        contents_velodyne = f.read()\n",
    "    # make velodyne\n",
    "    f2 = open(f'sample_data/object/translated/velodyne/{name}.bin','wb')\n",
    "    f2.write(contents_velodyne)\n",
    "    # read Carib_Ai_hub\n",
    "    with open(f'{path_calib}{image_name.split(\".\")[0]}.txt','r') as f:\n",
    "        contents_calib = f.readlines()\n",
    "    # Save Carib_kitti_format\n",
    "    with open(f'sample_data/object/translated/kitti_format_carib/{lidar_location}/{name}.txt','w') as f:\n",
    "        p0 = 'p0: 1056.437682 0.0 974.398942 0.0 0.0 1024.415886 583.178996 0.0 0.0 0.0 1.0 0.0'\n",
    "        p1 = 'p1: 1056.437682 0.0 974.398942 0.0 0.0 1024.415886 583.178996 0.0 0.0 0.0 1.0 0.0'\n",
    "        p3 = 'p3: 1056.437682 0.0 974.398942 0.0 0.0 1024.415886 583.178996 0.0 0.0 0.0 1.0 0.0'\n",
    "        tr_imu = 'Tr_imu_to_velo: -0.999069645887872 0.030746732104378723 -0.030240389058074302 0.9276477826710018 -0.030772133023495043 -0.9995263554968372 0.0003748284867846508 0.058829066929946106 -0.03021454111295518 0.0013050410383379344 0.999542584572174 0.21383619101949458'\n",
    "        f.write(p0 + '\\n' + p1 + '\\n' + contents_calib[0] + p3 + '\\n'  + contents_calib[1] + contents_calib[2] + tr_imu)\n",
    "    save_to_kitti_str = ''\n",
    "    for lidar_annotations in json_data['annotations']:\n",
    "        # read aihub annotation\n",
    "        category = str.title(str(lidar_annotations['3dbbox.category']))\n",
    "        # label category change\n",
    "        label_check_list = ['Truck', 'Bus', 'Car', 'Pedestrian', 'Bicycle']\n",
    "        if category not in label_check_list:\n",
    "            continue\n",
    "        if category == 'Truck' or category == 'Bus':\n",
    "            category = 'Car'\n",
    "        if category == 'Bicycle':\n",
    "            category = 'Cyclist'\n",
    "        truncated = str(lidar_annotations['3dbbox.truncated'])\n",
    "        occuluded = str(lidar_annotations['3dbbox.occluded'])\n",
    "        rotatin_y = str(lidar_annotations['3dbbox.rotation_y'])\n",
    "        l_3d, h_3d, w_3d = str(lidar_annotations['3dbbox.dimension'][0]), str(lidar_annotations['3dbbox.dimension'][1]), str(lidar_annotations['3dbbox.dimension'][2])\n",
    "        x_3d, y_3d, z_3d = str(lidar_annotations['3dbbox.location'][0]), str(lidar_annotations['3dbbox.location'][1]), str(lidar_annotations['3dbbox.location'][2])\n",
    "        z_3d_to_kitti = str(lidar_annotations['3dbbox.location'][2] - lidar_annotations['3dbbox.dimension'][1]/2)\n",
    "        rotatin_y = -(float(rotatin_y) + 1.5707963268)\n",
    "        while rotatin_y < -np.pi or rotatin_y > np.pi:\n",
    "            if rotatin_y < -np.pi:\n",
    "                rotatin_y += 2*np.pi\n",
    "            elif rotatin_y > np.pi:\n",
    "                rotatin_y -= 2*np.pi\n",
    "        rotatin_y = str(rotatin_y)\n",
    "        # translate lidar to camera\n",
    "        v_to_c= np.array(Tr_velo_to_cam)\n",
    "        V2C = np.reshape(v_to_c, [3, 4])\n",
    "        xyz_3d = np.array([[float(x_3d), float(y_3d), float(z_3d_to_kitti)]])\n",
    "        project_xyz_3d = project_velo_to_rect(V2C, xyz_3d, R0)\n",
    "        x_p,y_p,z_p = project_xyz_3d[0][0], project_xyz_3d[0][1], project_xyz_3d[0][2]\n",
    "        # check object position\n",
    "        if float(z_p) < 0 :\n",
    "            continue\n",
    "        p2_list = []\n",
    "        p2 = contents_calib[0][:-1]\n",
    "        p2 = p2.split(' ')[1:]\n",
    "        for i in p2:\n",
    "            p2_list.append(float(i))\n",
    "        p2 = np.array(p2_list).reshape([3,4])\n",
    "        x_min, y_min, x_max, y_max = ut.return_bboxes(float(x_p), float(y_p), float(z_p), float(h_3d), float(w_3d), float(l_3d), float(rotatin_y), p2)\n",
    "        save_to_kitti_str += f\"{category} {truncated} {occuluded} {rotatin_y} {x_min} {y_min} {x_max} {y_max} {h_3d} {w_3d} {l_3d} {str(x_p)} {str(y_p)} {str(z_p)} {rotatin_y}\\n\"\n",
    "    save_to_kitti_str = save_to_kitti_str[:-1]\n",
    "    if save_to_kitti_str == '':\n",
    "        return\n",
    "    # Save Lidar_to_cam\n",
    "    with open(f'sample_data/object/translated/lidar_to_cam/{lidar_location}/{name}.txt', 'w') as f:\n",
    "        f.write(save_to_kitti_str)\n",
    "    # make train.txt\n",
    "    f2 = open(f'sample_data/object/translated/ImageSets/train.txt','a')\n",
    "    f2.write(name + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Aihub to kitti\n",
    "for image_name in camera_path_list:\n",
    "    # Make json data\n",
    "    json_data_camera = make_json_data(path_camera,image_name)\n",
    "    json_data_fl = make_json_data(path_front_left,image_name)\n",
    "    json_data_fr = make_json_data(path_front_right,image_name)\n",
    "    json_data_roof = make_json_data(path_roof,image_name)\n",
    "\n",
    "    # read Tr_velo_to_cam , R0 from calib\n",
    "    Tr_velo_to_cam, R0 = read_calib_Tr_R0(path_calib,image_name)\n",
    "    \n",
    "    # make roof lidar label\n",
    "    aihub_to_kitti_format_camera_cordinate(json_data_roof, image_name,Tr_velo_to_cam, R0, 'roof')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cam_to_image\n",
    "def custom_get_label_objects(label_dir, idx):\n",
    "    label_filename = os.path.join(label_dir, f\"{idx}\")\n",
    "    return ut.read_label(label_filename)\n",
    "def get_calibration(calib_path, idx):\n",
    "    calib_filename = os.path.join(calib_path, f\"{idx}\")\n",
    "    return ut.Calibration(calib_filename)\n",
    "lidar_location = 'roof'\n",
    "path_label= f'./sample_data/object/translated/lidar_to_cam/{lidar_location}/'\n",
    "label_list = os.listdir(path_label)\n",
    "\n",
    "\n",
    "\n",
    "check_list_false = []\n",
    "\n",
    "for target in label_list:\n",
    "    CONFIG = {\n",
    "    \"calib_path\" : './sample_data/object/calib/front',\n",
    "    \"label_path\" : path_label,\n",
    "    \"image_path\" : './sample_data/object/image/front/',\n",
    "    \"target_idx\" : target,\n",
    "}\n",
    "    try:\n",
    "        target_objects = custom_get_label_objects(CONFIG['label_path'], CONFIG['target_idx'])\n",
    "        calib = get_calibration(CONFIG['calib_path'], CONFIG['target_idx'])\n",
    "        for obj in target_objects:\n",
    "            obj.print_object()\n",
    "        try:\n",
    "            target_image = cv2.cvtColor(cv2.imread(os.path.join(CONFIG['image_path'], f\"{CONFIG['target_idx'][:-4]}.jpg\")), cv2.COLOR_BGR2RGB)\n",
    "        except: \n",
    "            # print(f\"{CONFIG['target_idx'][:-4]}.jpg\")\n",
    "            target_image = cv2.cvtColor(cv2.imread(os.path.join(CONFIG['image_path'], f\"{CONFIG['target_idx'][:-4]}.jpg\")), cv2.COLOR_BGR2RGB)\n",
    "        img = ut.show_image_with_boxes(target_image, target_objects, calib)\n",
    "        cv2.imwrite(f'./sample_data/object/save_img/{lidar_location}/{target}.png',img)\n",
    "        # plt.imshow(img)\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-2-0934341d3a37>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-0934341d3a37>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('mmdet3d': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d735d120566e529380de39e77d787d041867a32ec388c45247ff44d2dcad908"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
